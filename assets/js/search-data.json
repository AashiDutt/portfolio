{
  
    
        "post0": {
            "title": "Different data augmentation recipes in `tf.keras` for image classification",
            "content": "Data augmentation is a favorite recipe among deep learning practitioners especially for the ones working in the field of computer vision. Data augmentation is a technique used for introducing variety in training data thereby helping to mitigate overfitting. . When using Keras for training image classification models, using the ImageDataGenerator class for handling data augmentation is pretty much a standard choice. However, with TensorFlow, we get a number of different ways we can apply data augmentation to image datasets. In this tutorial, we are going to discuss three such ways. Knowing about these different ways of plugging in data augmentation in your image classification training pipelines will help you decide the best way for a given scenario. . Here’s a brief overview of the different ways we are going to cover: . Using the standard ImageDataGenerator class | Using TensorFlow image ops with a TensorFlow dataset | Using Keras’s (experimental) image processing layers | Mix-matching different image ops &amp; image processing layers | . Let’s get started! . Experimental setup . We are going to use the flowers dataset to demonstrate the experiments. Downloading the dataset is just as easy as executing the following line of code: . flowers contains the path (which in my case is - /root/.keras/datasets/flower_photos) where the dataset got downloaded. The structure of the dataset looks like so - . ├── daisy [633 entries] ├── dandelion [898] ├── roses [641] ├── sunflowers [699 entries] ├── tulips [799 entries] └── LICENSE.txt . # Get the flowers dataset flowers = tf.keras.utils.get_file( &#39;flower_photos&#39;, &#39;https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz&#39;, untar=True) . Using the standard ImageDataGenerator class For most of the scenarios, the ImageDataGenerator should be good enough. Its flexible API design is really to follow and it makes it easier to work with custom image datasets by providing meaningful high-level abstractions. . We instantiate the ImageDataGenerator class like so - . img_gen = tf.keras.preprocessing.image.ImageDataGenerator( rescale=1./255, rotation_range=30, horizontal_flip=True) . We specify two augmentation operations and a pixel rescaling operation in there. ImageDataGenerator comes with a handy flow_from_directory method that allows us to read images from a directory and apply the specified operations on the fly during the time of training. Here’s how to instruct the img_gen object to read images from a directory - . IMG_SHAPE = 224 BATCH_SIZE = 32 img_flow = img_gen.flow_from_directory(flowers, shuffle=True, batch_size=BATCH_SIZE, target_size=(IMG_SHAPE, IMG_SHAPE)) . Found 3670 images belonging to 5 classes. . We then verify the images and the labels and they are indeed parsed right - . images, labels = next(img_flow) print(images.shape, labels.shape) show_batch(images, labels) . (32, 224, 224, 3) (32, 5) . Training with an ImageDataGenerator instance is extremely straight-forward - . model = get_training_model() model.fit(img_flow, ...) . For a fully worked out example, refer to this tutorial. . As can be seen in this blog post, ImageDataGenerator’s overall data loading performance can have a significant effect on how fast your model trains. To tackle situations, where you need to maximize the hardware utilization without burning unnecessary bucks, TensorFlow’s data module can be really helpful (comes at some costs). . TensorFlow image ops with tf.data APIs . The blog post I mentioned in the previous section shows the kind of performance boost achievable with tf.data APIs. But it’s important to note that boost comes at the cost of writing boilerplate code which makes the overall process more involved. For example, here’s how you would load and preprocess your images and labels - . def parse_images(image_path): # Load and preprocess the image img = tf.io.read_file(image_path) # read the raw image img = tf.image.decode_jpeg(img, channels=3) # decode the image back to proper format img = tf.image.convert_image_dtype(img, tf.float32) # scale the pixel values to [0, 1] img = tf.image.resize(img, [IMG_SHAPE, IMG_SHAPE]) # resize the image # Parse the labels label = tf.strings.split(image_path, os.path.sep)[5] return (img, label) . You would then write a separate augmentation policy with the TensorFlow Image ops - . def augment(image, label): img = tf.image.rot90(image) img = tf.image.flip_left_right(img) img = tf.clip_by_value(img, 0.0, 1.0) return (img, label) . To chain the above two together you would first create an initial dataset consisting of only the image paths - . image_paths = list(paths.list_images(flowers)) list_ds = tf.data.Dataset.from_tensor_slices((image_paths)) . Now, you would read, preprocess, shuffle, augment, and batch your dataset - . AUTO = tf.data.experimental.AUTOTUNE train_ds = ( list_ds .map(parse_images, num_parallel_calls=AUTO) .shuffle(1024) .map(augment, num_parallel_calls=AUTO) # augmentation call .batch(BATCH_SIZE) .prefetch(AUTO) ) . num_parallel_calls allows you to parallelize the mapping function and tf.data.experimental.AUTOTUNE lets TensorFlow decide the level of parallelism to use dynamically (how cool is that?). prefetch allows loading in the next batch of data well before your model finishes the current epoch of training. It is evident that this process is more involved than the previous one. . Verifying if we constructed the data input pipeline correctly is a vital step before you feed your data to the model - . image_batch, label_batch = next(iter(train_ds)) print(image_batch.shape, label_batch.shape) show_batch(image_batch.numpy(), label_batch.numpy(), image_data_gen=False) . (32, 224, 224, 3) (32,) . The “b”s appear before the class labels because TensorFlow parses the strings as byte-strings. Using train_ds with your model is also just about executing - . model = get_training_model() model.fit(train_ds, ...) . Here you can find a fully worked out example. Here you can know more about the different performance considerations when using tf.data. There are more image ops available with TensorFlow Addons which can found here. . Recently, Keras introduced image_dataset_from_directory function (on available in tf-nightly at the time of writing this) which takes care of many of the boilerplate code we saw above and still yields pretty good performance. Here’s a tutorial that shows how to use it. . Keras has also introduced a number of image processing layers which can be very useful to build flexible augmentation pipelines using the Sequential API. In the next section, let’s see how. . Using Keras&#8217;s (experimental) image processing layers . Just like you would construct an entire model using the Sequential API, you can now construct very flexible data augmentation pipelines using the newly introduced (although experimental at the time of writing this) image processing layers. If we were to convert the data augmentation operations we have been following in the tutorial so far, building a data augmentation pipeline using this approach would be like so - . data_augmentation = tf.keras.Sequential([ tf.keras.layers.experimental.preprocessing.RandomFlip(&#39;horizontal&#39;), tf.keras.layers.experimental.preprocessing.RandomRotation(0.3) ]) . Before passing your data through this stack of layers makes sure you haven’t applied any augmentation already. So, it’s safe to create a separate TensorFlow dataset without mapping the augmentation function like we previously did - . # Create TensorFlow dataset without any augmentation train_ds = ( list_ds .map(parse_images, num_parallel_calls=AUTO) .shuffle(1024) .batch(BATCH_SIZE) .prefetch(AUTO) ) . Now, we can see how to examine some of the augmented images that would come out of this mini pipeline - . image_batch, label_batch = next(iter(train_ds)) plt.figure(figsize=(10, 10)) for n in range(25): ax = plt.subplot(5, 5, n+1) augmented_image = data_augmentation(tf.expand_dims(image_batch[n], 0)) plt.imshow(augmented_image[0].numpy()) plt.title(label_batch[n].numpy()) plt.axis(&#39;off&#39;) . Note that these layers can be also added as a part of your model definition which makes them ideal candidates when doing test-time augmentation. Training a model with this pipeline baked in requires a different approach to follow since we cannot map it directly as we did in the previous section. This is why this approach needs a different treatment. A sample training pipeline using this approach may look like so - . # You define an input layer with pre-defined shapes inputs = keras.Input(shape=(IMG_SHAPE, IMG_SHAPE, 3)) x = data_augmentation(inputs) # apply random data augmentation x = feature_extractor_model(x, training=False) x = GlobalAveragePooling2D()(x) x = Dropout(0.2)(x) outputs = Dense(1)(x) model = Model(inputs, outputs) . Now, model should be good to go with - model.fit(train_ds, ...). A fully worked out example is available here. Note that, performance might get slightly affected when going with this approach. . Let’s now think about situations where we may need to use a combination of the image ops of TensorFlow and the layers we just saw. What if we need to plug in custom augmentation operations in the augmentation pipeline? Added on top of it, what if we need to fix the probability at which the augmentation operations would get applied? Data augmentation pipelines are quite central behind the success of recent works like SimCLR, Augmix, etc. . Towards more complex augmentation pipelines . In this final approach, we will see how to mix and match between the different stock image ops, and stock image processing layers. Let’s first define a class utilizing the stock image ops with a utility function to apply them at random with a pre-defined probability. . class CustomAugment(object): def __call__(self, image): # Random flips and grayscale with some stochasticity img = self._random_apply(tf.image.flip_left_right, image, p=0.5) img = self._random_apply(self._color_drop, img, p=0.8) return img def _color_drop(self, x): image = tf.image.rgb_to_grayscale(x) image = tf.tile(x, [1, 1, 1, 3]) return x def _random_apply(self, func, x, p): return tf.cond( tf.less(tf.random.uniform([], minval=0, maxval=1, dtype=tf.float32), tf.cast(p, tf.float32)), lambda: func(x), lambda: x) . _random_apply is taken from the official SimCLR repository. Now, in order to tie it together with the stock image processing layers, we can still use the Sequential API with a Lambda layer - . # Build the augmentation pipeline data_augmentation = tf.keras.Sequential([ tf.keras.layers.Lambda(CustomAugment()), tf.keras.layers.experimental.preprocessing.RandomRotation(0.1) ]) . When we verify if it’s indeed correct, we get desired outputs - . image_batch, label_batch = next(iter(train_ds)) plt.figure(figsize=(10, 10)) for n in range(25): ax = plt.subplot(5, 5, n+1) augmented_image = data_augmentation(tf.expand_dims(image_batch[n], 0)) plt.imshow(augmented_image[0].numpy()) plt.title(label_batch[n].numpy()) plt.axis(&#39;off&#39;) . Training models when using this approach remains the same as the previous one. Keep in mind that performance can get affected when using this approach. . References . Fine-tuning with Keras and Deep Learning | Transfer learning &amp; fine-tuning | Image classification from scratch | Data augmentation | .",
            "url": "https://sayak.dev/tf.keras/data_augmentation/image/2020/05/10/augmemtation-recipes.html",
            "relUrl": "/tf.keras/data_augmentation/image/2020/05/10/augmemtation-recipes.html",
            "date": " • May 10, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Sharing your work online effectively",
            "content": "Well, you have put a lot of blood and sweat into writing your latest blog post on Machine Learning. Don&#39;t let your struggle go in vain and let the world know about it. Sharing your blog posts across different channels not only gives you exposure but also may get you tremendous feedback on your work. In my personal experience, the feedback has been super useful for me to improve myself not only as a writer but also as a communicator. There can be times you might have missed out on a super important detail, or you might have unknowingly introduced a snazzy bug in the code listings of your blog -- those things could have been caught in the process of feedback interchange. . In this short article, I am going to enlist a few different ways to share your work and get feedback. Note your work can be anything starting from a crucial GitHub PR, to a weekend project. Although the following platforms and communities are mostly limited to Machine Learning, I hope this guide will be useful for tech bloggers in general. . Sharing on platforms/communities . Before I start the sharing process, I generally create a Google Doc to effectively keep track of where I am sharing my work. This essentially acts as a checklist for all the places I want to share my work on. Here&#39;s the template I follow for creating the Google Doc - . Link to where the work has been posted. | Brief description of the work. | Post table: . . | . I generally keep the description to a maximum of 280 characters so that I can use it on Twitter as well. . Now, turning to the platforms and communities, here are some recommendations (in no particular order): . HackerNews (https://news.ycombinator.com/newest) | Made With ML (https://madewithml.com/) | Reddit r/MachineLearning | r/MachinesLearn | r/learnmachinelearning | r/deeplearning | . | Twitter | Facebook AIDL | Montreal AI | Deep Learning | . | Fast.ai Forum (https://forums.fast.ai/) | LinkedIn | Google Groups (depends on the framework used in the work) discuss@tensorflow.org | tflite@tensorflow.org | tfjs@tensorflow.org | tfx@tensorflow.org | . | . While sharing my work, I find it to be important to always attach a brief description. Additionally, if your work is related to implementing research work, you should definitely include it on Papers with Code. . Sharing to aid discussions . You might be active on online forums like Quora, StackOverflow, and so on. While participating in a discussion in those forums you can make effective use of your work if it is relevant. In these cases, the approach is to not just supply a link to your work, but also to first write about any important pointers relevant to the discussion first, and then supply the link to your work to better aid it. Let&#39;s say there&#39;s a discussion going on the topic of &quot;What is Weight Initialization in Neural Nets?&quot; Here&#39;s how I would approach my comment: . A neural net can be viewed as a function with learnable parameters and those parameters are often referred to as weights and biases. Now, while starting the training of neural nets these parameters (typically the weights) are initialized in a number of different ways - sometimes, using constant values like 0’s and 1’s, sometimes with values sampled from some distribution (typically a uniform distribution or normal distribution), sometimes with other sophisticated schemes like Xavier Initialization. The performance of a neural net depends a lot on how its parameters are initialized when it is starting to train. Moreover, if we initialize it randomly for each run, it’s bound to be non-reproducible (almost) and even not-so-performant too. On the other hand, if we initialize it with constant values, it might take way too long to converge. With that, we also eliminate the beauty of randomness which in turn gives a neural net the power to reach covergence quicker using gradient-based learning. We clearly need a better way to initialize it. Careful initialization of weights helps us to train them better. To know more, please follow this article of mine. . Well, that&#39;s it for now. I hope it proves to be useful for you. Please provide any suggestions you may have via the comments. I am thankful to Alessio of FloydHub for sharing these tips with me. .",
            "url": "https://sayak.dev/blogs/sharing/2020/04/20/sharing-work-effectively.html",
            "relUrl": "/blogs/sharing/2020/04/20/sharing-work-effectively.html",
            "date": " • Apr 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Embedding an image preprocessing function in a `tf.keras` model",
            "content": "In this tutorial, we are going to see how to embed a simple image preprocessing function within a trained model (tf.keras) while exporting it for serving. This is a useful feature to have because it can help us reduce a lot of boilerplate code needed while using any model for serving purposes. With this capability, you get a lot more flexibility and modularity to your model. . Data loading, preprocessing, and visualization . To keep things simple we will be using the FashionMNIST dataset. Note that these techniques can easily be applied to more complex models as well (with some limitation). . We are not going to preprocess the images before hand. We will let the model do it. . # Load data (x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data() . # Class labels (don&#39;t change the order) CLASSES = [&quot;T-shirt/top&quot;, &quot;Trouser&quot;, &quot;Pullover&quot;, &quot;Dress&quot;, &quot;Coat&quot;, &quot;Sandal&quot;, &quot;Shirt&quot;, &quot;Sneaker&quot;, &quot;Bag&quot;, &quot;Ankle boot&quot;] . # Show a few examples from the train set plt.figure(figsize=(10,10)) for i in range(25): plt.subplot(5,5,i+1) plt.xticks([]) plt.yticks([]) plt.grid(True) plt.imshow(x_train[i], cmap=plt.cm.binary) plt.xlabel(CLASSES[y_train[i]]) plt.show() . Model building and training . We are good to proceed towards building and training a neural network. We will first define a simple preprocessing function to scale the pixel values and then we will embed it into the model using a Lambda layer. You can replace this anything fancy you would want. . We will use a shallow network architecture so that we can train it quickly. . # Define the preprocessing function # We will embed it in the model later def preprocess_image(image_pixels): img = image_pixels / 255 return img # A humble model def get_training_model(): # Construct the model using the Functional API input_layer = tf.keras.layers.Input(shape=(28, 28), name=&quot;input_layer&quot;) preproc_layer = tf.keras.layers.Lambda(preprocess_image, name=&quot;lambda_layer&quot;)(input_layer) # Preprocessing function flatten = tf.keras.layers.Flatten()(preproc_layer) dense_1 = tf.keras.layers.Dense(128, activation=&quot;relu&quot;)(flatten) dropout = tf.keras.layers.Dropout(0.2)(dense_1) outputs = tf.keras.layers.Dense(len(CLASSES), activation=&quot;softmax&quot;)(dropout) # Create the model model = tf.keras.models.Model(input_layer, outputs) # Compile the model and return it model.compile(optimizer=&#39;adam&#39;, loss=&#39;sparse_categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;]) return model . # Topology of the model tf.keras.utils.plot_model(get_training_model(), show_shapes=True) . The Lambda layer is our preprocessing layer. . # Train the model for 10 epochs apparel_model = get_training_model() history = apparel_model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=128) . Epoch 1/10 469/469 [==============================] - 2s 4ms/step - loss: 0.6004 - accuracy: 0.7937 - val_loss: 0.4682 - val_accuracy: 0.8347 Epoch 2/10 469/469 [==============================] - 2s 4ms/step - loss: 0.4246 - accuracy: 0.8495 - val_loss: 0.4089 - val_accuracy: 0.8521 Epoch 3/10 469/469 [==============================] - 2s 4ms/step - loss: 0.3795 - accuracy: 0.8642 - val_loss: 0.3928 - val_accuracy: 0.8564 Epoch 4/10 469/469 [==============================] - 2s 4ms/step - loss: 0.3576 - accuracy: 0.8711 - val_loss: 0.3632 - val_accuracy: 0.8687 Epoch 5/10 469/469 [==============================] - 2s 4ms/step - loss: 0.3407 - accuracy: 0.8762 - val_loss: 0.3593 - val_accuracy: 0.8688 Epoch 6/10 469/469 [==============================] - 2s 4ms/step - loss: 0.3294 - accuracy: 0.8788 - val_loss: 0.3532 - val_accuracy: 0.8721 Epoch 7/10 469/469 [==============================] - 2s 4ms/step - loss: 0.3165 - accuracy: 0.8846 - val_loss: 0.3609 - val_accuracy: 0.8685 Epoch 8/10 469/469 [==============================] - 2s 4ms/step - loss: 0.3084 - accuracy: 0.8859 - val_loss: 0.3503 - val_accuracy: 0.8701 Epoch 9/10 469/469 [==============================] - 2s 4ms/step - loss: 0.2982 - accuracy: 0.8915 - val_loss: 0.3560 - val_accuracy: 0.8713 Epoch 10/10 469/469 [==============================] - 2s 4ms/step - loss: 0.2886 - accuracy: 0.8929 - val_loss: 0.3381 - val_accuracy: 0.8776 . Now that we have a trained model, we can go ahead and export it and then we will see how to use it on new images for inference. . Sample test image and model export . We are getting close. Now that we have a trained model here are the things we would do from here: . Serialize a randomly selected image from the test set. | Export the model and parse model predictions. | . Let&#39;s go. . Step 1: Serializing a randomly selected image from the test set . # Select a random image from the test set for serialization sampe_test_img_id = np.random.choice(x_test.shape[0], 1) sampe_test_img = x_test[sampe_test_img_id].squeeze() # Remove the batch dimension sampe_test_img = (sampe_test_img * 255).astype(&quot;int32&quot;) # Scale back to integer # Verify image label and shape print(&quot;Image class: &quot;,CLASSES[y_test[int(sampe_test_img_id)]]) print(sampe_test_img.shape) . Image class: Ankle boot (28, 28) . #hide_output # Serialize the image cv2.imwrite(&quot;sample_image.png&quot;, sampe_test_img) . Note that while writing a grayscale image, OpenCV adds the channel dimension of 3 to it. We will need to handle carefully. . # Make sure the serialized image is good to go plt.imshow(plt.imread(&quot;sample_image.png&quot;), cmap=plt.cm.binary) plt.show() . Step 2: Model exporting and parsing predictions . Let&#39;s first serialize our model and load it. . # Serialize the model and load it apparel_model.save(&quot;apparel_model.h5&quot;) restored_model = tf.keras.models.load_model(&quot;apparel_model.h5&quot;) . WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer. . This warning is not desirable. When the optimizer is loaded with a fresh state, the model predictions can be erroneous. So, to resolve this problem we will only be serializing the weights of the model with the save_weights() function. There can be other nuances like this when you work with Lambda layers and you can check this article out to know about them. . apparel_model.save_weights(&quot;apparel_model.h5&quot;) . We will now initialize a dummy model with the same architecture as the one we trained and we will then load the weights of our trained model into it. . restored_model = get_training_model() restored_model.load_weights(&quot;apparel_model.h5&quot;) . Now we should be good to go with the predictions part. First, let&#39;s load the image we serialized in step 1. As mentioned before, OpenCV adds 3-channels to grayscale images while saving them. We can take care of this issue with cv2.cvtColor(image_pixels, cv2.COLOR_BGR2GRAY). . # Load the image image_pixels = cv2.imread(&quot;sample_image.png&quot;) image_pixels = cv2.cvtColor(image_pixels, cv2.COLOR_BGR2GRAY) # Preview the image plt.imshow(image_pixels, cmap=plt.cm.binary) plt.show() . # Run inference and parse the prediction class_probabilities = restored_model.predict(np.expand_dims(image_pixels, 0))[0] print(&quot;Predicted &quot;,CLASSES[np.argmax(class_probabilities)]) . Predicted Ankle boot . We can see that it is working as expected. . # Load and *preprocess* data (x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data() x_train = x_train / 255 x_test = x_test / 255 . Taking it a step further with concrete functions and SavedModel . The SavedModel format is the standard serialization format in TensorFlow 2.x since it communicates very well with the entire TensorFlow ecosystem. Be it GCP AI Platform, be it tf.keras, be it TFLite, etc,, SavedModel format unifies the entire ecosystem. For serializing custom models (developed using subclassing) SavedModel would be needed as well. . In this section, let&#39;s see how can we do the same i.e. embed a preprocessing function inside a model so that it can be serialized in the SavedModel format. . Step 1: Create a sequential model without any preprocessing layer . def get_training_model_v2(): # Construct the model using the Functional API input_layer = tf.keras.layers.Input(shape=(28, 28), name=&quot;input_layer&quot;) flatten = tf.keras.layers.Flatten()(input_layer) dense_1 = tf.keras.layers.Dense(128, activation=&quot;relu&quot;)(flatten) dropout = tf.keras.layers.Dropout(0.2)(dense_1) outputs = tf.keras.layers.Dense(len(CLASSES), activation=&quot;softmax&quot;)(dropout) # Create the model model = tf.keras.models.Model(input_layer, outputs) # Compile the model and return it model.compile(optimizer=&quot;adam&quot;, loss=&quot;sparse_categorical_crossentropy&quot;, metrics=[&quot;accuracy&quot;]) return model . Step 2: Train it! . # Train the model for 10 epochs apparel_model_v2 = get_training_model_v2() history = apparel_model_v2.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=128) . Epoch 1/10 469/469 [==============================] - 2s 4ms/step - loss: 0.5995 - accuracy: 0.7914 - val_loss: 0.4549 - val_accuracy: 0.8347 Epoch 2/10 469/469 [==============================] - 2s 4ms/step - loss: 0.4200 - accuracy: 0.8501 - val_loss: 0.4094 - val_accuracy: 0.8520 Epoch 3/10 469/469 [==============================] - 2s 4ms/step - loss: 0.3823 - accuracy: 0.8616 - val_loss: 0.3831 - val_accuracy: 0.8635 Epoch 4/10 469/469 [==============================] - 2s 4ms/step - loss: 0.3575 - accuracy: 0.8713 - val_loss: 0.3896 - val_accuracy: 0.8563 Epoch 5/10 469/469 [==============================] - 2s 4ms/step - loss: 0.3405 - accuracy: 0.8758 - val_loss: 0.3569 - val_accuracy: 0.8720 Epoch 6/10 469/469 [==============================] - 2s 4ms/step - loss: 0.3249 - accuracy: 0.8813 - val_loss: 0.3490 - val_accuracy: 0.8733 Epoch 7/10 469/469 [==============================] - 2s 4ms/step - loss: 0.3176 - accuracy: 0.8840 - val_loss: 0.3480 - val_accuracy: 0.8735 Epoch 8/10 469/469 [==============================] - 2s 4ms/step - loss: 0.3055 - accuracy: 0.8878 - val_loss: 0.3355 - val_accuracy: 0.8809 Epoch 9/10 469/469 [==============================] - 2s 4ms/step - loss: 0.2971 - accuracy: 0.8914 - val_loss: 0.3331 - val_accuracy: 0.8792 Epoch 10/10 469/469 [==============================] - 2s 4ms/step - loss: 0.2905 - accuracy: 0.8920 - val_loss: 0.3344 - val_accuracy: 0.8808 . Step 3: SavedModel plunge . Okay! Now we are ready to the crux of the section. We will first create a custom model class (inherited from tf.keras.Model) and it will contain two things: . A model that is loaded with the weights of a trained model | A serving function that will contain the preprocessing function along with the necessary signature. | . # A custom class for serving class ExportModel(tf.keras.Model): def __init__(self, model): super().__init__(self) self.model = model @tf.function(input_signature=[tf.TensorSpec([None, 28, 28], dtype=tf.uint8)]) def my_serve(self, images): images = tf.cast(images, tf.float32) / 255 # pre-processing probabilities = self.model(images) # prediction from model class_index = tf.argmax(probabilities, axis=-1) # post-processing return {&quot;class_index&quot;: class_index} . my_serve is our serving function. You can see that is decorated with tf.function and the reason behind doing so is it allows us to embed an arbitrary function in a model&#39;s graph which can later be exported using the SavedModel format. . We can also see - input_signature=[tf.TensorSpec([None, 28, 28], dtype=tf.uint8)]. This is needed in order to indicate which part of the model&#39;s graph would be needed while serving. By specifying tf.TensorSpec([None, 28, 28], we instruct the function that the inputs should respect this shape - [None, 28, 28] and the dtype argument is self-explanatory. . We will get to why the return type of the function is done in such a way - {&quot;class_index&quot;: class_index} in a moment. . If you are interested to know more using SavedModel and different serialization options that come with it, be sure to check this tutorial out. . Step 4: Instantiate a dummy model and set its weights . # Set the weights of this dummy model to the weights of the model we trained restored_model = get_training_model_v2() restored_model.set_weights(apparel_model_v2.get_weights()) . Step 5: Export the model and run inference . Now, to serialize the model in the SavedModel format we will make use of tf.saved_model.save. It can automatically determine which input signature to use for serving for most of the models if the details are available. However, in our case, it won&#39;t be able to do so. So, we will need to explicitly indicate which function to use as the signature while serving. . export_path = &quot;/content/saved_model/1/&quot; tf.keras.backend.set_learning_phase(0) # Make sure no weight update happens serving_model = ExportModel(restored_model) # Instantiate a model with the preprocessing function tf.saved_model.save(serving_model, export_path, signatures={&#39;serving_default&#39;: serving_model.my_serve}) . WARNING:tensorflow:Skipping full serialization of Keras layer &lt;__main__.ExportModel object at 0x7f4096b7b358&gt;, because it is not built. WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating: If using Keras pass *_constraint arguments to layers. INFO:tensorflow:Assets written to: /content/saved_model/1/assets . By specifying &#39;serving_default&#39;: serving_model.my_serve we instructed tf.saved_model.save about which signature to use for serving. Now if we inspect what all were saved, things should seem consistent. For this we are going to use the saved_model_cli command-line interpreter. . !saved_model_cli show --dir /content/saved_model/1 --tag_set serve --signature_def serving_default . The given SavedModel SignatureDef contains the following input(s): inputs[&#39;images&#39;] tensor_info: dtype: DT_UINT8 shape: (-1, 28, 28) name: serving_default_images:0 The given SavedModel SignatureDef contains the following output(s): outputs[&#39;class_index&#39;] tensor_info: dtype: DT_INT64 shape: (-1) name: StatefulPartitionedCall:0 Method name is: tensorflow/serving/predict . So, we can see that the configuration that is expected from the inputs and the outputs of the serialized model is consistent with what we had instructed. We returned the outputs in form a dictionary (namely class_index) in my_serve and we can see that as well. . We can also do the inspection in Pythonic ways. . loaded = tf.saved_model.load(&quot;/content/saved_model/1/&quot;) print(list(loaded.signatures.keys())) # This signature will be used while serving . [&#39;serving_default&#39;] . # Output configuration infer = loaded.signatures[&quot;serving_default&quot;] print(infer.structured_outputs) . {&#39;class_index&#39;: TensorSpec(shape=(None,), dtype=tf.int64, name=&#39;class_index&#39;)} . Let&#39;s finally run the inference! . # Load the sample image image_pixels = cv2.imread(&quot;sample_image.png&quot;) image_pixels = cv2.cvtColor(image_pixels, cv2.COLOR_BGR2GRAY) . # Run inference CLASSES[infer(tf.constant(image_pixels))[&quot;class_index&quot;].numpy()[0]] . &#39;Ankle boot&#39; . We can see that the prediction is correct in this case as well. So, when we ran infer = loaded.signatures[&quot;serving_default&quot;] we essentially loaded a concrete function i.e. we loaded my_serve. Remember we assigned the value of serving_default in the beginning of this section? . With infer(tf.constant(image_pixels)) we are simply running our input image through the concrete function and we are parsing the output from the dictionary (class_index being the key) it returns . . References . MNIST on TPU (Tensor Processing Unit) or GPU using tf.Keras and tf.data.Dataset | Using the SavedModel format | .",
            "url": "https://sayak.dev/tf.keras/preprocessing/2020/04/13/embedding-image-preprocessing-functions.html",
            "relUrl": "/tf.keras/preprocessing/2020/04/13/embedding-image-preprocessing-functions.html",
            "date": " • Apr 13, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "I am Sayak (সায়ক). I am currently with PyImageSearch where I apply deep learning to solve real-world problems in computer vision and bring some of the solutions to edge devices. I am also responsible for providing Q&amp;A support to PyImageSearch readers. . Previously at DataCamp, I developed projects (here and here), and practice pools (here) for DataCamp. Prior to DataCamp, I have worked at TCS Research and Innovation (TRDDC) on Data Privacy. There, I was a part of TCS’s critically acclaimed GDPR solution called Crystal Ball. . Off the work, I enjoy writing technical articles and talking at developer meetups and conferences. My subject of interest broadly lies in areas like Machine Learning Interpretability, Full-Stack Data Science. . GitHub | LinkedIn | Twitter | ResearchGate | Email | . Timeline: . PyImageSearch (June, 2019 - present) | DataCamp (August 2018 - June 2019) (on contract) | TCS Research and Innovation (January 2018 - August 2018) | Tata Consultancy Services Limited (July 2017 - January 2018) | CareerIn (Dec, 2016 - Feb, 2017) (intern) | . Badges I proudly endorse: . . . An honour to be their son 🙂 . Tapas Kumar Paul | Baby Paul | .",
          "url": "https://sayak.dev/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  
      ,"page2": {
          "title": "Authoring",
          "content": "Co-authored a book Hands-On Python Deep Learning for the Web with Anubhav Singh (Packt Publishers). . Authored a liveProject namely Use Machine Learning to Detect Phishing Websites with Manning Publishers. . Authored two DataCamp Projects (Predicting Credit Card Approvals and Analyze International Debt Statistics) and a DataCamp Practice Pool on Advanced Deep Learning with Keras. . Below are the blogs, articles, and tutorials I have written on Data Science, Machine Learning and more. . Datacamp . KMeans clustering with scikit-learn - https://goo.gl/dT7kYq | DBSCAN: A macroscopic investigation in Python - https://goo.gl/fDGYUn | Hyperparameter Optimization in Machine Learning Models - https://goo.gl/5C6ouV | Towards Preventing Overfitting: Regularization - https://goo.gl/B9vxia | Ensemble Learning in Python - https://goo.gl/dmH9db | Investigating Tensors with PyTorch - https://goo.gl/yoYsVL | Introduction to Feature Selection - https://goo.gl/gY8rwy | Demystifying crucial Statistics in Python - https://goo.gl/i2Wm5v 1 | Diving Deep with Imbalanced Data - https://goo.gl/fZnYmV | Introduction to Cyclical Learning Rates - https://goo.gl/2fpkQQ | Turning Machine Learning Models into APIs in Python2 - https://goo.gl/vwzqtA | Essentials of Linear Regression in Python3 - https://goo.gl/5nuVmt | Simplifying Sentiment Analysis in Python - https://goo.gl/62mEJo | Automated Machine Learning with Auto-Keras - https://goo.gl/XEjea4 | Introduction to Indexing in SQL - https://goo.gl/7dcnE7 | Understanding Recursive Functions in Python - https://goo.gl/u1U2eH | Beginner’s Guide to Google’s Vision API in Python - https://goo.gl/VCwZa8 | Beginner’s Guide to PostgreSQL - https://goo.gl/DV1rhY | Managing Databases in PostgreSQL - https://goo.gl/YA9fAy | Working with Spreadsheets in SQL - https://goo.gl/PYUb2v | Installing PostgreSQL on Windows and Mac OS X - https://goo.gl/CyF8T4 | Using Order By Keyword in SQL - https://goo.gl/i7mD8f | Introduction to Alter Table Statement in SQL - https://goo.gl/qWi3km | SQLite in Python - https://goo.gl/wYCr4e | Introduction to Where Clause in SQL - https://goo.gl/VB3CdX | Introduction to SQL Joins - https://goo.gl/2w342W | 10 command-line utilities in PostgreSQL - https://goo.gl/xFWbRS | CASE Statements in PostgreSQL - https://bit.ly/2HWBSwu | Aggregate Functions in SQL - https://bit.ly/2GnDqg9 | Cleaning Data in SQL - http://bit.ly/2GyPdrL | Materialized Views in PostgreSQL - http://bit.ly/2VFz11x | Argument Parsing in Python - http://bit.ly/2LOWGsJ | Ten Important Updates from TensorFlow 2.0 - http://bit.ly/2EHENWL | Implementing Neural Style Transfer using TensorFlow 2.0 - http://bit.ly/2J1mmxv | TensorFlow 2.0 Case Study - http://bit.ly/2U0yjZA | . FloydHub . Introduction to Anomaly Detection in Python - https://bit.ly/2TZLg4d | Introduction to K-Means Clustering in Python with scikit-learn - https://bit.ly/2IZev5a | An introduction to Q-Learning: Reinforcement Learning - http://bit.ly/2HxuVzo | How to plan and execute your ML and DL projects - http://bit.ly/2XtMCeh | Becoming One With the Data (FloydHub) - [http://bit.ly/30N3bPA] 4 | Training Neural Nets: a Hacker’s Perspective - http://bit.ly/training-neural-nets | . Weights and Biases . Running Hyperparameter Sweeps to Pick the Best Model - http://bit.ly/2MKHR7K | arXiv Search: Generating Tags from Paper Titles - http://bit.ly/2WQ8sFh | How to Use GCP with Weights &amp; Biases - http://bit.ly/399Fd60 | Mixed precision training with tf.keras - http://bit.ly/2RIkQ9z | Customizing Training Loops in TensorFlow 2.0 - http://bit.ly/39DOmEf | Bayesian Hyperparameter Optimization - A Primer - http://bit.ly/38SqXgR | Visualize models in TensorBoard with Weights and Biases - http://bit.ly/3cCP5qq | The effects of weight initialization on neural nets - https://bit.ly/3bk34Qu | Introduction to image inpainting with deep learning - https://bit.ly/39CqTBK (Joint work with Ayush Thakur) | Kaggle Starter Kernel - Jigsaw Multilingual Toxic Comment Classification - https://bit.ly/2UQtnbB | Distributed training in tf.keras with W&amp;B - https://bit.ly/2JZkQwJ | Reproducible Models with W&amp;B - https://bit.ly/34V5ZNz | EvoNorm layers in TensorFlow 2 - https://bit.ly/3arUw9q | Transfer Learning with EfficientNet family of models - https://bit.ly/2zMJVcE | A Tale of Model Quantization in TF Lite - https://bit.ly/3dlCRSI | . Other . Your First Machine Learning Project: Q and A with Sayak Paul, Google Developer Expert (GDE) in Machine Learning (Ep. 4) | AMA with Sayak Paul - Hacktoberfest’19 - https://fossassam.tech/post/ama-sayak/ | Predicting the publisher’s name from an article: A case study (for Google Developers Experts’ Medium Channel) - http://bit.ly/2K9TpS8 5 | A comprehensive list of data science resources for developers (for Intel DevMesh) - https://intel.ly/2J2UYSs | Detecting phishing websites using machine learning (Intel Software Innovators’ Medium Channel) - http://bit.ly/2YBvaAs | Lessons learned from a Deep Learning Hackathon (Intel Software Innovators’ Medium Channel) - http://bit.ly/2YfnZhI | Introduction to procedures and cursors in SQL (Towards Data Science) - https://bit.ly/2OTd8WF | “Reparameterization” trick in Variational Autoencoders (Towards Data Science) - https://bit.ly/2RjoWnM | . This article got featured in “Python Top 10 Articles for the Past Month (v.Oct 2018)” and secured a rank of 4. &#8617; . | This article got featured in “Machine Learning Top 10 Articles for the Past Month (v.Nov 2018)” and secured a rank of 9. &#8617; . | This article got featured in “Python Top 10 Articles for the Past Month (v.Dec 2018)” and secured a rank of 10. &#8617; . | Featured in Sebastian Ruder’s monthly newsletter. &#8617; . | This one won the ML GDE Dev Challenge &#8617; . |",
          "url": "https://sayak.dev/authoring/",
          "relUrl": "/authoring/",
          "date": ""
      }
      
  

  
      ,"page3": {
          "title": "Education",
          "content": "(The formal ones may be) . B.Tech in IT from Netaji Subhash Engineering College (2013 - 17) (Final year dissertation: A CFS–DNN-Based Intrusion Detection System) | High School from Jadavpur Vidyapith (PCMC) (2005 - 13) | Certifications relevant to my subject of interest: Introduction to Data Science in Python (University of Michigan) | Data Scientist with Python Track (DataCamp) | Data Analyst with Python Track (DataCamp) | Deep Learning Specialization (deeplearning.ai) | Advanced Machine Learning with TensorFlow on Google Cloud Platform | TensorFlow in Practice Specialization (deeplearning.ai) | TensorFlow: Data and Deployment Specialization (deeplearning.ai) | . | .",
          "url": "https://sayak.dev/education/",
          "relUrl": "/education/",
          "date": ""
      }
      
  

  

  
      ,"page5": {
          "title": "Interviews",
          "content": "The purpose of conducting these interviews is to mainly get insights about the real-world project experiences, perspectives on learning new things, some fun facts and thereby enriching the communities in the process. I sincerely thank the interviewees for taking the time out from their busy schedules and for agreeing to do these interviews. Here are the interviews I have done so far - . An interview with Robert Crowe, Developer Advocate (TensorFlow) at Google | An interview with Snehasis Banerjee, Scientist at TCS Research and Innovation | An interview with Abhishek Kumar, Senior Manager, Data Science at Publicis Sapient | An interview with Laurence Moroney, Developer Advocate at Google | An interview with Karl Fezer, AI Ecosystem Evangelist at Arm | An interview with Dan Becker, Team Lead of Kaggle Learn &amp; Product Lead of Kaggle Kernels | An interview with Rajarshee Mitra, Data Scientist at Microsoft | An interview with Alessio, Lead Data Scientist at FloydHub | An interview with Joel Grus, Research Engineer at Allen Institute for Artificial Intelligence | An interview with Josh Tobin, Research Scientist at OpenAI | An interview with Andrew Ferlitsch, Developer Program Engineer at Google | An interview with Shalini De Mello, Principal Research Scientist at NVIDIA | An interview with Rahul Agrawal, Principal Machine Learning Manager at AI and Research, Microsoft | An interview with Aakash Nain, Research Engineer at Ola | An interview with Xander Steenbrugge, Machine Learning Researcher &amp; YouTuber at “Arxiv Insights” | An interview with Ines Montani, Co-founder at Explosion | An interview with Girish Palshikar, Principal Scientist at TCS Research and Innovation | An interview with Christoph Molnar, Interpretable Machine Learning Researcher | An interview with Leslie Smith, Senior Research Scientist at U.S. Naval Research Laboratory | An interview with Arindam Pal, Senior Research Scientist at CSIRO | An interview with Ankur Patel, Vice President of Data Science at 7Park Data | An interview with Max Pumperla, Deep Learning Engineer at Skymind | An interview with Abhishek Thakur, Data Scientist, and Kaggle 3x Grandmaster | An interview with Dmytro Mishkin, Computer Vision Researcher | An interview with Ellick Chan, Head of University Relations and Research — Intel AI Academy | An interview with Thomas Wolf, Chief Science Officer at Hugging Face | An interview with Dat Tran, Head of AI at Axel Springer AI | An interview with Daniel Seita, Ph.D. student at UC, Berkeley | An interview with Vladimir Iglovikov, Senior Computer Vision Engineer at Lyft | An interview with Hamel Husain, Staff Machine Learning Engineer at GitHub | An interview with Patrick Hall, Principal Scientist at bnh.ai and Advisor to H2O.ai | An interview with Colin Raffel, Research Scientist at Google | .",
          "url": "https://sayak.dev/interviews/",
          "relUrl": "/interviews/",
          "date": ""
      }
      
  

  
      ,"page6": {
          "title": "Research",
          "content": "I am interested in the following problems (with no particular deadline). This page also enlists the publications I have been a part of. . Some research problems/problems I wish to solve: . Surveillance for water wastage: Water wastage is a vicious problem. In spite of several campaigns and infinite awareness activities, water wastage is still an avid problem. In countries like India especially in its rural areas, this problem imposes a great threat. The aim of this work is to facilitate modern image processing and information retrieval techniques to extract the relevant images from satellite image data and to build an effective surveillance system to reduce the amount of water wastage. | Information extraction from Annual Report: Most companies report their annual financial statements every year formally on their company website. This is typically published in a PDF format, with the financial data usually presented in the form of tables. The financial reports of companies are utilized by banks and other financial institutions to evaluate company performances to enable these institutions to approve loans or manage other transactions with these institutions. A huge amount of manual effort is spent by financial institutions today to fetch these financial reports and extract the financial data from reports. The objective is to automate this extraction process to minimize the manual effort. This will enable companies to increase their productivity and save considerable effort. | Generate Corporate profiles from the Web: When a company engages with their clients and establishes a relationship, it does an initial KYC (Know Your Customer), to get background information about the company and its key stakeholders and employees, like the list of C-Level executives of their client and their designations, HQ address, Phone numbers etc. The KYC is done manually by users for every client, which usually runs into hundreds of thousands of clients for some large companies. Fetching profile information from either company websites or from public search engines is a tedious effort and takes considerable time. The objective of this use case is to automate the information extraction process and save on effort and increase productivity. | Towards intelligent food safety and food distribution: Food wastage and poor quality are genuine problems in many countries like India. How can we facilitate AI techniques in order to maintain a good safety and distribution trade-off in food-care. | . *I am open to discuss/collaborate on these problems . Publications: . Paul S., Banerjee C., Ghoshal M. (2018) A CFS–DNN-Based Intrusion Detection System. In: Bera R., Sarkar S., Chakraborty S. (eds) Advances in Communication, Devices and Networking. Lecture Notes in Electrical Engineering, vol 462. Springer, Singapore. | Gupta J., Paul S., Ghosh A. (2019) A Novel Transfer Learning-Based Missing Value Imputation on Discipline Diverse Real Test Datasets—A Comparative Study with Different Machine Learning Algorithms. In: Abraham A., Dutta P., Mandal J., Bhattacharya A., Dutta S. (eds) Emerging Technologies in Data Mining and Information Security. Advances in Intelligent Systems and Computing, vol 814. Springer, Singapore. | C. Baneriee, S. Paul and M. Ghoshal, A Comparative Study of Different Ensemble Learning Techniques Using Wisconsin Breast Cancer Dataset, 2017 International Conference on Computer, Electrical &amp; Communication Engineering (ICCECE), Kolkata, India, 2017, pp. 1-6. | S. Sengupta, S. Basak, P. Saikia, S. Paul et al., A review of deep learning with special emphasis on architectures, applications and recent trends, Knowledge-Based Systems (2020) 105596, https://doi.org/10.1016/j.knosys.2020.105596. | .",
          "url": "https://sayak.dev/research/",
          "relUrl": "/research/",
          "date": ""
      }
      
  

  
  

  
  

  

  
      ,"page10": {
          "title": "Talks/Seminars/Workshops",
          "content": "I take the idea of learning and sharing very seriously and hence the existence of this page. I love to attend developer meetups, conferences, workshops and learn from them as much as I can. I sometimes talk on a range of topics that I love the most. All the slides of my talks/sessions can be found here. . Given by me: . Presented our paper A CFS–DNN-Based Intrusion Detection System at International Conference on Communication Devices and Networking, Sikkim Manipal Institute of Technology, Sikkim, June 3, 2017. | Presented our paper A Comparative Study of Different Ensemble Learning Techniques Using Wisconsin Breast Cancer Dataset, at International Conference on Computer, Electrical &amp; Communication Engineering, Techno India University, Kolkata, December 23, 2017. | Co-presented our paper A Novel Transfer Learning-Based Missing Value Imputation on Discipline Diverse Real Test Datasets—A Comparative Study with Different Machine Learning Algorithms at International Conference on Emerging Technologies in Data Mining and Information Security, University of Engineering and Management, Kolkata, February 23, 2018. | Spoke on Cyclical Learning Rates for training Neural Nets at DevFest Kolkata, November 3, 2018. | Conducted a hack-session on Cyclical Learning Rates at DataHack Summit (organized by Analytics Vidhya), Bangalore, November 23, 2018. | Delivered talks on Introduction to BigQuery at GDG Kolkata Cloud Study Jam (Academy of Technology), Google Cloud Next ‘19 Extended - Kolkata on April 12 and April 19, 2019 respectively. | Conducted a session on Ten Updates Introduced in TensorFlow 2.0 along with a short quiz at Google I/O Extended 2019, Kolkata, May 11, 2019. | Conducted a session on Training neural nets: A methodical approach at ML/AR Developer Day organized by GDG Kolkata and DSC HIT (May 30, 2019). Conducted the same session but in a more detailed manner at ML With The Experts - GDG Kolkata Meetup (July 7, 2019). | . | Spoke at Google I/O Extended 2019, Bhubaneswar on Ten Updates Introduced in TensorFlow 2.0, June 9, 2019. Also shared a few opportunities with the students (link to the Opportunities’ deck). | Spoke at DevFest Kolkata 2019 about how to approach the process of model deployment, August 3, 2019. My talk was titled Connecting Flutter with TensorFlow 2.0. Link to the slides, video and the GitHub repository. | Spoke at DevFest Jaipur 2019 (September 08, 2019) on Structuring Machine Learning Projects. Remotely presented on this topic at DevFest Izmir 2019 (November 23, 2019). Here’s the modified deck. | . | Spoke at Explore ML Academy on Problem Framing and How to find data set and fairness practices, September 14, 2019, Hyderabad. | Spoke at DevFest Bhubaneswar 2019 (September 22, 2019) on The Human Loop in Machine Learning. | Spoke at DevFest Goa 2019 (September 29, 2019) on Training Neural Nets: a Hacker’s Perspective. Spoke at Class III of Launchpad Accelerator India (October 16, 2019), Bangalore on an extended version of the same topic. Deck: http://bit.ly/LPA_3. | Remotely presented on this topic at DevFest Warsaw &amp; Radzymin 2019 (December 7, 2019). | . | Presented my work on Blood Cell Detection using TensorFlow Object Detection API at TensorFlow Roadshow, Bangalore (October 01, 2019). Deck: http://bit.ly/tf-roadshow-sayak. | Remotely presented my work on Predicting Publisher’s Names from Hackernews Article Titles at Global GDE Summit (October 26, 2019). Video available here (Courtesy: Akshay Bahadur). Deck: http://bit.ly/GDESummit19. | Remotely presented at Machine Learning Weekend, Turkey on Building data pipelines with tf.data (November 3, 2019). | Presented at Kaggle Days Mumbai on On the learning dynamics of neural nets (November 30, 2019). | Conducted a workshop on Applied Deep Learning using TensorFlow 2.0 and GCP (includes topics like data pipeline optimization, cyclical learning rates, mixed-precision training and so on) at Launchpad India Accelerator Bootcamp (December 12 - 13, 2019). Content available here: http://bit.ly/mlb-code-sayak. | Spoke at DevLoop on Your first machine learning project, Ganpat University, Gujrat, India (January 04, 2020). Deck: http://bit.ly/dloop20. | Spoke at Improving machine learning model on Weights and Biases for better machine learning, Bangalore (February 08, 2020). Deck: http://bit.ly/blr-wb. | Spoke at Sigma 2020 on Machine Learning: For the Community by the Community, Kolkata (February 12, 2020). | Spoke at MENA Digital Days 2020 on Building data pipelines with tf.data. Deck here, session video here. | Spoke for GDG Goa at an online event on Hello, TensorFlow. Deck here, session here. | Spoke for GDG Pune and WTM Pune on Doing more with TensorFlow Lite, April 26, 2020. | Spoke for Global AI Hub, Turkey on Gotchas of Transfer Learning for Image Classification, May 01, 2020. A recording of the session is available here. | Spoke on TensorFlow Hub: Models, Models, and Models for TFUG Hyderabad on May 03, 2020. Deck: http://bit.ly/tf-hub. A recording of the session is available here. | . Co-organized by me: . Full-Stack Data Science Workshop along with The Code Foundation and GDG Kolkata, Kolkata, January 19, 2019. | DevFest Kolkata, August 3, 2019. | TensorFlow All-Around Kolkata, August 31, 2019. | Let’s Build, January 4, 2020. | from tfug import kolkata, February 15, 2020. | Kolkata Kreate, February 29, 2020. | . Note: If you are interested to invite me as a speaker for your event, please get in touch by dropping an email at spsayakpaul@gmail.com. If you are interested in having me submit a CFP first, that is absolutely fine! Please don’t hesitate to ask that. .",
          "url": "https://sayak.dev/talksseminarsworkshops/",
          "relUrl": "/talksseminarsworkshops/",
          "date": ""
      }
      
  

  
      ,"page11": {
          "title": "XYZ",
          "content": "Beta-tester of DataCamp’s course Deep Learning in Python | Taught under-privileged children and managed operations for a TCS-CSR initiative called H20 (Helping Hand Organization) | Moderator of the Artificial Intelligence channel of Campus Commune | Mentored for Smart India Hackathon 2018 and Smart India Hackathon 2019 | Advisor to Overleaf, an online LaTex platform | Contributing author at Towards Data Science | Mentored for GirlScript Summer of Code 2019 | Book reviewer at Manning Publications Co | Co-organizer at GDG Kolkata | Organizer at TensorFlow User Group Kolkata | Mentored at Launchpad Women Entrepreneurs | Mentored at Explore ML Academy, Hyderabad | Mentored at AI Hack Tunisia | Mentored at Class III (2019) of Launchpad Accelerator India (Tweet by GoogleDevsIN) | Mentored at Google Code-in for TensorFlow through December, 2019 - January 2020 (Certificate) | Mentored at Build For Digital India Bootcamps through January 2020 - February 2020 (Tweet by GoogleDevsIN) | Mentored at Explore ML Bootcamp, Hyderabad (Tweet by GoogleDevsIN) | . Non-tech: . I love listening to all genres of music. A guitar player myself. Have played in a band Behest from 2013 to 2017. | I love watching TV serieses also (Narcos, Gotham, Fringe, Seal Team, Ozark being all time favorites). | .",
          "url": "https://sayak.dev/xyz/",
          "relUrl": "/xyz/",
          "date": ""
      }
      
  

  
  

  
  

  
  

  
      ,"page15": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://sayak.dev/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}